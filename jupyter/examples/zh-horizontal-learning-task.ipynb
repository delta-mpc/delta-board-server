{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14971e9",
   "metadata": {},
   "source": [
    "# 横向联邦学习任务示例\n",
    "\n",
    "这是一个使用Delta框架编写的横向联邦学习的任务示例。\n",
    "\n",
    "数据是分布在多个节点上的[MNIST数据集](http://yann.lecun.com/exdb/mnist/)，每个节点上只有其中的一部分样本。任务是训练一个卷积神经网络的模型，进行手写数字的识别。\n",
    "\n",
    "本示例可以直接在Deltaboard中执行并查看结果。<span style=\"color:#FF8F8F;font-weight:bold\">在点击执行之前，需要修改一下个人的Deltaboard API的地址，具体请看下面第4节的说明。</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef1746",
   "metadata": {},
   "source": [
    "## 1. 引入需要的包\n",
    "\n",
    "我们的计算逻辑是用torch写的。所以首先引入```numpy```和```torch```，以及一些辅助的工具，然后从```delta-task```的包中，引入Delta框架的内容，包括```DeltaNode```节点，用于调用API发送任务，用于横向联邦学习任务```HorizontalLearning```，以及用于配置安全聚合策略的```FaultTolerantFedAvg```等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Iterable, List, Tuple\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL.Image import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from delta.delta_node import DeltaNode\n",
    "from delta.task.learning import HorizontalLearning, FaultTolerantFedAvg\n",
    "import delta.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741239a",
   "metadata": {},
   "source": [
    "## 2. 定义神经网络模型\n",
    "\n",
    "接下来我们来定义神经网络模型，这里和传统的神经网络模型定义完全一样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46faaabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, 5, padding=2)\n",
    "        self.pool1 = torch.nn.AvgPool2d(2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, 5)\n",
    "        self.pool2 = torch.nn.AvgPool2d(2, stride=2)\n",
    "        self.dense1 = torch.nn.Linear(400, 100)\n",
    "        self.dense2 = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 400)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88618f57",
   "metadata": {},
   "source": [
    "## 3. 定义隐私计算任务\n",
    "\n",
    "然后可以开始定义我们的横向联邦任务了，用横向联邦学习的方式，在多节点上训练上面定义的神经网络模型\n",
    "\n",
    "在定义横向联邦学习任务时，有几部分内容是需要用户自己定义的：\n",
    "\n",
    "* ***任务配置***: 我们需要在 ```super().__init__()``` 方法中对任务进行配置。 这些配置项包括任务名称（```name```），任务训练的总轮数（```max_rounds```），执行验证的频率（每 ```validate_interval``` 轮执行一次验证），验证集的比例（```validate_frac```），以及安全聚合的策略（```strategy```）。 \n",
    "* ***数据集***: 我们需要在```dataset```方法中定义任务所需要的数据集。 该方法返回一个```delta.dataset.Dataset```实例， 其参数```dataset```代表所需数据集的名称。关于数据集格式的具体细节，请参考[这篇文章](https://docs.deltampc.com/network-deployment/prepare-data)。\n",
    "* ***训练集的Dataloader***: 我们需要在```make_train_dataloader```方法中定义训练集的Dataloader。在该方法中，会根据在```dataset```方法中的配置，传入相应的训练集作为参数（一个```torch.utils.data.Dataset```实例），在方法中，可以按照需要对数据集进行变换、预处理等操作。最后，我们需要返回一个```torch.utils.data.Dataloader```实例，它会作为模型训练方法的输入。\n",
    "* ***验证集的Dataloader***: 我们需要在```make_validate_dataloader```方法中定义验证集的Dataloader。 在该方法中，所需要实现的逻辑与```make_train_dataloader```非常类似，除了该方法的输入是验证集，返回的也是验证集的Dataloader。\n",
    "* ***模型训练***: 在该方法中，定义整个模型的训练过程，包含整个前向传播和后向传播的。该方法的输入是训练集的Dataloader。\n",
    "* ***模型验证***: 在该方法中，定义整个模型的验证过程。该方法的输入是验证集的Dataloader，输出是一个字典，字典的键是计算出的指标名称，值是对应的指标值。\n",
    "* ***State dict***: 我们需要在```state_dict```方法中定义所有需要训练和更新的模型参数，方法的返回值就是这些模型参数的列表。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3012646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data: List[Tuple[Image, str]]):\n",
    "    \"\"\"\n",
    "    作为dataloader的collate_fn，用于预处理函数。\n",
    "    将输入的mnist图片调整大小、归一化后，变为torch.Tensor返回。\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for x, y in data:\n",
    "        xs.append(np.array(x).reshape((1, 28, 28)))\n",
    "        ys.append(int(y))\n",
    "\n",
    "    imgs = torch.tensor(xs)\n",
    "    label = torch.tensor(ys)\n",
    "    imgs = imgs / 255 - 0.5\n",
    "    return imgs, label\n",
    "\n",
    "\n",
    "class Example(HorizontalLearning):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            name=\"example\",  # 任务名称，用于在Deltaboard中的展示\n",
    "            max_rounds=2,  # 任务训练的总轮次，每聚合更新一次权重，代表一轮\n",
    "            validate_interval=1,  # 验证的轮次间隔，1表示每完成一轮，进行一次验证\n",
    "            validate_frac=0.1,  # 验证集的比例，范围(0,1)\n",
    "            strategy=FaultTolerantFedAvg(  # 安全聚合的策略，可选策略目前包含 FedAvg和FaultTolerantFedAvg，都位于delta.task.learning包下\n",
    "                min_clients=2,  # 算法所需的最少客户端数，至少为2\n",
    "                max_clients=3,  # 算法所支持的最大客户端数，必须大雨等于min_clients\n",
    "                merge_epoch=1,  # 聚合更新的间隔，merge_interval_epoch表示每多少个epoch聚合更新一次权重\n",
    "                wait_timeout=30,  # 等待超时时间，用来控制一轮计算的超时时间\n",
    "                connection_timeout=10  # 连接超时时间，用来控制流程中每个阶段的超时时间\n",
    "            )\n",
    "        )\n",
    "        self.model = LeNet()\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=0.1,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-3,\n",
    "            nesterov=True,\n",
    "        )\n",
    "\n",
    "    def dataset(self) -> delta.dataset.Dataset:\n",
    "        \"\"\"\n",
    "        定义任务所需要的数据集。\n",
    "        return: 一个delta.dataset.Dataset\n",
    "        \"\"\"\n",
    "        return delta.dataset.Dataset(dataset=\"mnist\")\n",
    "\n",
    "    def make_train_dataloader(self, dataset: Dataset) -> DataLoader:\n",
    "        \"\"\"\n",
    "        定义训练集Dataloader，可以对dataset进行各种变换、预处理等操作。\n",
    "        dataset: 训练集的Dataset\n",
    "        return: 训练集的Dataloader\n",
    "        \"\"\"\n",
    "        return DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True, collate_fn=transform_data)  # type: ignore\n",
    "\n",
    "    def make_validate_dataloader(self, dataset: Dataset) -> DataLoader:\n",
    "        \"\"\"\n",
    "        定义验证集Dataloader，可以对dataset进行各种变换、预处理等操作。\n",
    "        dataset: 验证集的Dataset\n",
    "        return: 验证集的Dataloader\n",
    "        \"\"\"\n",
    "        return DataLoader(dataset, batch_size=64, shuffle=False, drop_last=False, collate_fn=transform_data)  # type: ignore\n",
    "\n",
    "    def train(self, dataloader: Iterable):\n",
    "        \"\"\"\n",
    "        训练步骤\n",
    "        dataloader: 训练数据集对应的dataloader\n",
    "        return: None\n",
    "        \"\"\"\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.loss_func(y_pred, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def validate(self, dataloader: Iterable) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        验证步骤，输出验证的指标值\n",
    "        dataloader: 验证集对应的dataloader\n",
    "        return: Dict[str, float]，一个字典，键为指标的名称（str），值为对应的指标值（float）\n",
    "        \"\"\"\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        ys = []\n",
    "        y_s = []\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.loss_func(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "            y_ = torch.argmax(y_pred, dim=1)\n",
    "            y_s.extend(y_.tolist())\n",
    "            ys.extend(y.tolist())\n",
    "        avg_loss = total_loss / count\n",
    "        tp = len([1 for i in range(len(ys)) if ys[i] == y_s[i]])\n",
    "        precision = tp / len(ys)\n",
    "\n",
    "        return {\"loss\": avg_loss, \"precision\": precision}\n",
    "\n",
    "    def state_dict(self) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        需要训练、更新的模型参数\n",
    "        在聚合更新、保存结果时，只会更新、保存get_params返回的参数\n",
    "        return: List[torch.Tensor]， 模型参数列表\n",
    "        \"\"\"\n",
    "        return self.model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ac7be-75ef-47a8-a82c-5aedf6095f33",
   "metadata": {},
   "source": [
    "## 4. 指定执行任务用的Delta Node的API\n",
    "\n",
    "定义好了任务，我们就可以开始准备在Delta Node上执行任务了。\n",
    "\n",
    "Delta Task框架可以直接调用Delta Node API发送任务到Delta Node开始执行，只要在任务执行时指定Delta Node的API地址即可。\n",
    "\n",
    "Deltaboard提供了对于Delta Node的API的封装，为每个用户提供了一个独立的API地址，支持多人同时使用同一个Delta Node，并且能够在Deltaboard中管理自己提交的任务。\n",
    "在这里，我们使用Deltaboard提供的API来执行任务。如果用户自己搭建了Delta Node，也可以直接使用Delta Node的API。\n",
    "\n",
    "在左侧导航栏中进入“个人中心”，在Deltaboard API中，复制自己的API地址，并粘贴到下面的代码中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d30aac-f019-4544-81f9-0af16ea4a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_NODE_API = \"http://127.0.0.1:6704\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ad5fa",
   "metadata": {},
   "source": [
    "## 5. 执行隐私计算任务\n",
    "\n",
    "接下来我们可以开始运行这个模型了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Example().build()\n",
    "delta_node = DeltaNode(DELTA_NODE_API)\n",
    "delta_node.create_task(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9994ef7e",
   "metadata": {},
   "source": [
    "## 6. 查看执行状态\n",
    "点击执行后，可以从输出的日志看出，任务已经提交到了Delta Node的节点上。\n",
    "\n",
    "接下来，可以从左侧的导航栏中，前往“任务列表”，找到刚刚提交的任务，点击进去查看具体的执行日志了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
