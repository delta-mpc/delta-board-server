{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# An Example of the Horizontal Federated Learning Task\r\n",
    "\r\n",
    "This is an example of running horizontal federated learning Delta Task on multiple Delta Nodes.\r\n",
    "\r\n",
    "The data ([MNIST Dataset](http://yann.lecun.com/exdb/mnist/)) is distributed on several nodes with each node only having partial dataset.\r\n",
    "And the task is to train a Convolutional Neural Network model to identify hand-writing digits.\r\n",
    "\r\n",
    "This example could be executed in Deltaboard directly. <span style=\"color:#FF8F8F;font-weight:bold\">Before hitting the run button, the Delta Node API address should be modified according to the user's config, the instructions are explained in section 4 below.</span>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import the Required Packages\r\n",
    "\r\n",
    "The computation logic is written in Torch. So we must import ```numpy``` and ```torch```, and some other helper tools. Then we need to import Delta Task framework components from Python package ```delta-task``` including ```DeltaNode``` for Delta Node API connection and ```HorizontalTask``` that we'll run in this example:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import Dict, Iterable, List, Tuple, Any, Union\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "\r\n",
    "from delta import DeltaNode\r\n",
    "from delta.task import HorizontalTask\r\n",
    "from delta.algorithm.horizontal import FedAvg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define the Neural Network Model\r\n",
    "\r\n",
    "Now let's define the CNN model, which is exactly the same as what we will do before:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LeNet(torch.nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, 5, padding=2)\r\n",
    "        self.pool1 = torch.nn.AvgPool2d(2, stride=2)\r\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, 5)\r\n",
    "        self.pool2 = torch.nn.AvgPool2d(2, stride=2)\r\n",
    "        self.dense1 = torch.nn.Linear(400, 100)\r\n",
    "        self.dense2 = torch.nn.Linear(100, 10)\r\n",
    "\r\n",
    "    def forward(self, x: torch.Tensor):\r\n",
    "        x = self.conv1(x)\r\n",
    "        x = torch.relu(x)\r\n",
    "        x = self.pool1(x)\r\n",
    "        x = self.conv2(x)\r\n",
    "        x = torch.relu(x)\r\n",
    "        x = self.pool2(x)\r\n",
    "\r\n",
    "        x = x.view(-1, 400)\r\n",
    "        x = self.dense1(x)\r\n",
    "        x = torch.relu(x)\r\n",
    "        x = self.dense2(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define the Horizontal Federated Learning Task\r\n",
    "\r\n",
    "The next step is to define our horizontal federated learning task to train the above model on multiple nodes.\r\n",
    "\r\n",
    "There're several parts in the PPC Task that need to be programmed by the developer:\r\n",
    "\r\n",
    "* ***Model Training Method***: Including what loss function and optimizer are used, and how to perform training steps.\r\n",
    "* ***Data Pre-process Method***: Before performing training step, the function ```preprocess``` could be used to transform the training data. For detailed explanation of the arguments, please refer to [this document](https://docs.deltampc.com/network-deployment/prepare-data).\r\n",
    "* ***Model Validation Method***: How to calculate precision score on each iteration.\r\n",
    "* ***Horizontal Federated Learning Config***: The minimum/maximum number of nodes required to start an iteration, number of max steps, etc.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ExampleTask(HorizontalTask):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__(\r\n",
    "            name=\"example\", # The task name which is used for displaying purpose.\r\n",
    "            dataset=\"mnist\", # The file/folder name of the dataset used. The file/folder should be placed under the data folder of all the Delta Nodes.\r\n",
    "            max_rounds=2,  # The number of total rounds of training. In every round, all the nodes calculate their own partial results, and summit them to the server.\r\n",
    "            validate_interval=1,  # The number of rounds after which we calculate a validation score.\r\n",
    "            validate_frac=0.1,  # The ratio of samples for validate set in the whole dataset，range in (0,1)\r\n",
    "        )\r\n",
    "        \r\n",
    "        # Pass in the NN model we just defined\r\n",
    "        self.model = LeNet()\r\n",
    "        \r\n",
    "        # Define the loss function\r\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\r\n",
    "        \r\n",
    "        # Define the optimizer\r\n",
    "        self.optimizer = torch.optim.SGD(\r\n",
    "            self.model.parameters(),\r\n",
    "            lr=0.1,\r\n",
    "            momentum=0.9,\r\n",
    "            weight_decay=1e-3,\r\n",
    "            nesterov=True,\r\n",
    "        )\r\n",
    "\r\n",
    "    def preprocess(self, x, y=None):\r\n",
    "        \"\"\"\r\n",
    "        The data pre-processing method.\r\n",
    "        After data loading, every sample is passed through this method to be transformed.\r\n",
    "        For the detailed explanation of the input arguments, please refer to https://docs.deltampc.com/network-deployment/prepare-data\r\n",
    "        x: a sample from the dataset, the type depends on the data provided.\r\n",
    "        y: the lable of the sample, None if no label is attached to the sample.\r\n",
    "        return: the data and label after processing, the type should be torch.Tensor or np.ndarray\r\n",
    "        \"\"\"\r\n",
    "        x /= 255.0\r\n",
    "        x *= 2\r\n",
    "        x -= 1\r\n",
    "        x = x.reshape((1, 28, 28))\r\n",
    "        return torch.from_numpy(x), torch.tensor(int(y), dtype=torch.long)\r\n",
    "\r\n",
    "    def train(self, dataloader: Iterable):\r\n",
    "        \"\"\"\r\n",
    "        The training step defination.\r\n",
    "        dataloader: the dataloader corresponding to the dataset.\r\n",
    "        return: None\r\n",
    "        \"\"\"\r\n",
    "        for batch in dataloader:\r\n",
    "            x, y = batch\r\n",
    "            y_pred = self.model(x)\r\n",
    "            loss = self.loss_func(y_pred, y)\r\n",
    "            self.optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            self.optimizer.step()\r\n",
    "\r\n",
    "    def validate(self, dataloader: Iterable) -> Dict[str, float]:\r\n",
    "        \"\"\"\r\n",
    "        Validation method.\r\n",
    "        To calculate validation scores on each node after several training steps.\r\n",
    "        The result will also go through the secure aggregation before sending back to server.\r\n",
    "        dataloader: the dataloader corresponding to the dataset.\r\n",
    "        return: Dict[str, float], A dictionary with each key (str) corresponds to a score's name and the value (float) to the score's value.\r\n",
    "        \"\"\"\r\n",
    "        total_loss = 0\r\n",
    "        count = 0\r\n",
    "        ys = []\r\n",
    "        y_s = []\r\n",
    "        for batch in dataloader:\r\n",
    "            x, y = batch\r\n",
    "            y_pred = self.model(x)\r\n",
    "            loss = self.loss_func(y_pred, y)\r\n",
    "            total_loss += loss.item()\r\n",
    "            count += 1\r\n",
    "\r\n",
    "            y_ = torch.argmax(y_pred, dim=1)\r\n",
    "            y_s.extend(y_.tolist())\r\n",
    "            ys.extend(y.tolist())\r\n",
    "        avg_loss = total_loss / count\r\n",
    "        tp = len([1 for i in range(len(ys)) if ys[i] == y_s[i]])\r\n",
    "        precision = tp / len(ys)\r\n",
    "\r\n",
    "        return {\"loss\": avg_loss, \"precision\": precision}\r\n",
    "\r\n",
    "    def get_params(self) -> List[torch.Tensor]:\r\n",
    "        \"\"\"\r\n",
    "        The params that need to be trained.\r\n",
    "        Only the params returned by this function will be updated and saved during aggregation.\r\n",
    "        return: List[torch.Tensor]， The list of model params.\r\n",
    "        \"\"\"\r\n",
    "        return list(self.model.parameters())\r\n",
    "\r\n",
    "    def algorithm(self):\r\n",
    "        \"\"\"\r\n",
    "        Algorithm used to perform result aggregation. All the candidates are included in the package delta.algorithm.horizontal\r\n",
    "        \"\"\"\r\n",
    "        return FedAvg(\r\n",
    "            merge_interval_epoch=0,  # The number of epochs to run before aggregation is performed.\r\n",
    "            merge_interval_iter=20,  # The number of iterations to run before aggregation is performed. One of this and the above number must be 0.\r\n",
    "            wait_timeout=10,  # Timeout when waiting for node participanting.\r\n",
    "            connection_timeout=10,  # Connection timeout in each communation in the aggreation algorithm.\r\n",
    "            min_clients=2,  # Minimum nodes required in each round.\r\n",
    "            max_clients=2,  # Maximum nodes allowed in each round.\r\n",
    "        )\r\n",
    "\r\n",
    "    def dataloader_config(\r\n",
    "        self,\r\n",
    "    ) -> Union[Dict[str, Any], Tuple[Dict[str, Any], Dict[str, Any]]]:\r\n",
    "        \"\"\"\r\n",
    "        the config for dataloaders of training and validating，\r\n",
    "        each config is a dictionary corresponding to the dataloader config of PyTorch.\r\n",
    "        The details are in https://pytorch.org/docs/stable/data.html\r\n",
    "        return: One or two Dict[str, Any]. When returning one dict, it is used for both training and validating dataloader.\r\n",
    "        \"\"\"\r\n",
    "        train_config = {\"batch_size\": 64, \"shuffle\": True, \"drop_last\": True}\r\n",
    "        val_config = {\"batch_size\": 64, \"shuffle\": False, \"drop_last\": False}\r\n",
    "        return train_config, val_config\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Set the API Address of the Delta Node\r\n",
    "\r\n",
    "After defining the task details, we're ready to run the task on the Delta Nodes.\r\n",
    "\r\n",
    "Delta Task framework could send the task to Delta Node directly, as long as the Delta Node API address is specified.\r\n",
    "\r\n",
    "Here we use the Delta Node API provided by Deltaboard. Deltaboard provides a separate API address for each of its users, the tasks submitted by the API could be listed inside Deltaboard. The developer could also use API from Delta Node directly.\r\n",
    "\r\n",
    "Click \"Profiles\" on the sidebar of Deltaboard, copy the API Address in Deltaboard API section, and paste it here:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DELTA_NODE_API = \"http://127.0.0.1:6704\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Run the PPC Task\n",
    "\n",
    "Finally we can start the task:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    task = ExampleTask()\r\n",
    "\r\n",
    "    delta_node = DeltaNode(DELTA_NODE_API)\r\n",
    "    delta_node.create_task(task)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Check the Running Status\r\n",
    "\r\n",
    "After clicking the run button, some logs will be print out showing the task is submitted to the Delta Node successfully.\r\n",
    "\r\n",
    "To see the task execution details, go to \"My Tasks\" on the sidebar of Deltaboard, the task should be listed.\r\n",
    "Click the item to view the execution logs."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}